{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'enable_notebook' from 'IPython.display' (c:\\Users\\dedbl\\anaconda3\\lib\\site-packages\\IPython\\display.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m simple_preprocess\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparsing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m STOPWORDS\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m display, enable_notebook\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyLDAvis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgensim_models\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgensimvis\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'enable_notebook' from 'IPython.display' (c:\\Users\\dedbl\\anaconda3\\lib\\site-packages\\IPython\\display.py)"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from IPython.display import display\n",
    "import os\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed.txt\n",
      "heavenearthjest.txt\n",
      "knot.txt\n",
      "seeing.txt\n",
      "spring.txt\n",
      "winter.txt\n",
      "How many chapters are there?  6\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'C:\\\\Users\\\\dedbl\\\\Documents\\\\anniedilliard\\\\chapters'  # Specify the path to your folder containing .txt files\n",
    "chapters = []\n",
    "chapter_names = []\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.txt'):\n",
    "        print(file_name)\n",
    "        chapter_names.append(file_name.rstrip(\".txt\"))\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            file_content = file.read()\n",
    "            chapters.append(file_content)\n",
    "print(\"How many chapters are there? \",len(chapters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STOPWORDS :  frozenset({'whereas', 'further', 'even', 'nowhere', 'ie', 'moreover', 'just', 'well', 'eight', 'some', 'beyond', 'former', 'with', 'himself', 'whose', 'several', 'themselves', 'thru', 'doing', 'yourselves', 'part', 'she', 'no', 'fifteen', 'whereafter', 'either', 'mostly', 'seems', 'and', 'become', 'wherever', 'others', 'above', 'elsewhere', 'within', 'very', 'an', 'never', 'light', 'our', 'from', 'herself', 'around', 'did', 'make', 'last', 'hers', 'whenever', 'amongst', 'who', 'we', 'meanwhile', 'cannot', 'thin', 'computer', 'seem', 'top', 'third', 'for', 'until', 'ever', 'because', 'behind', 'a', 'less', 'too', 'while', 'used', 'somewhere', 'twelve', 'etc', 'someone', 'were', 'anyway', 'you', 'formerly', 'many', 'do', 'it', 'but', 'perhaps', 'didn', 'always', 'various', 'below', 'nevertheless', 'could', 'hereupon', 'somehow', 'five', 'into', 'are', 'unless', 'beside', 'sometimes', 'so', 'them', 'yourself', 'still', 'yours', 'once', 'thereby', 'whereby', 'back', 'everywhere', 'itself', 'cry', 'each', 'twenty', 'her', 'therefore', 'seeming', 'both', 'must', 'side', 'due', 'already', 'since', 'upon', 'done', 'km', 'regarding', 'amoungst', 'ten', 'ourselves', 'move', 'bill', 'where', 'per', 'keep', 'at', 'enough', 'indeed', 'whether', 'against', 'mill', 'that', 'have', 'everything', 'eleven', 'under', 'de', 'should', 'nothing', 'without', 'un', 'don', 'take', 'was', 'thereafter', 'every', 'although', 'amount', 'might', 'about', 'whoever', 'together', 'empty', 'wherein', 'fire', 'thereupon', 'whole', 'whatever', 'is', 'sky', 'nor', 'except', 'therein', 'neither', 'onto', 'will', 'their', 'more', 'throughout', 'full', 'noone', 'fifty', 'on', 'bottom', 'thence', 'fill', 'down', 'ours', 'anywhere', 'namely', 'whom', 'becoming', 'now', 'after', 'few', 'as', 'using', 'off', 'such', 'towards', 'six', 'out', 'had', 'anyone', 're', 'two', 'be', 'con', 'seemed', 'find', 'name', 'my', 'if', 'something', 'see', 'only', 'does', 'none', 'him', 'of', 'than', 'water', 'nine', 'why', 'like', 'thick', 'forty', 'became', 'kg', 'has', 'may', 'inc', 'before', 'he', 'its', 'or', 'anyhow', 'most', 'yet', 'again', 'whence', 'interest', 'first', 'sometime', 'would', 'this', 'eg', 'they', 'by', 'me', 'describe', 'then', 'sixty', 'your', 'own', 'co', 'everyone', 'herein', 'really', 'alone', 'least', 'sincere', 'system', 'among', 'made', 'hereafter', 'afterwards', 'myself', 'please', 'us', 'three', 'there', 'hence', 'through', 'what', 'i', 'whereupon', 'another', 'quite', 'though', 'else', 'four', 'get', 'thus', 'often', 'can', 'whither', 'during', 'toward', 'latter', 'found', 'latterly', 'between', 'beforehand', 'cant', 'hereby', 'hundred', 'the', 'one', 'say', 'put', 'otherwise', 'hasnt', 'nobody', 'saw', 'becomes', 'rather', 'these', 'all', 'detail', 'here', 'day', 'to', 'front', 'next', 'same', 'ltd', 'those', 'any', 'tinker', 'give', 'not', 'am', 'other', 'over', 'however', 'in', 'serious', 'creek', 'show', 'being', 'call', 'couldnt', 'which', 'how', 'up', 'anything', 'across', 'his', 'much', 'besides', 'annie', 'go', 'mine', 'when', 'been', 'via', 'also', 'doesn', 'almost', 'along'})\n"
     ]
    }
   ],
   "source": [
    "# Add additional stopwords to the STOPWORDS set\n",
    "additional_stopwords = set(['creek', 'tinker', 'annie', 'like', 'water', 'saw', 'light', 'sky', 'day'])  # Replace with your stopwords\n",
    "STOPWORDS |= additional_stopwords\n",
    "\n",
    "# Now the STOPWORDS set contains the original stopwords plus the additional ones\n",
    "print(\"STOPWORDS : \",STOPWORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data, tokenises\n",
    "def preprocess(text):\n",
    "    return [token for token in simple_preprocess(text) if token not in STOPWORDS]\n",
    "\n",
    "processed_chapters = [preprocess(chapter) for chapter in chapters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary and corpus\n",
    "dictionary = corpora.Dictionary(processed_chapters)\n",
    "corpus = [dictionary.doc2bow(chapter) for chapter in processed_chapters]  #  Bag-of-Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 0.000*\"egg\" + 0.000*\"world\" + 0.000*\"looked\" + 0.000*\"wind\" + 0.000*\"time\" + 0.000*\"way\" + 0.000*\"snow\" + 0.000*\"ice\" + 0.000*\"dillard\" + 0.000*\"green\"\n",
      "Topic 2: 0.000*\"time\" + 0.000*\"long\" + 0.000*\"ice\" + 0.000*\"looked\" + 0.000*\"tree\" + 0.000*\"snow\" + 0.000*\"eyes\" + 0.000*\"winter\" + 0.000*\"world\" + 0.000*\"woods\"\n",
      "Topic 3: 0.005*\"eyes\" + 0.004*\"snow\" + 0.004*\"birds\" + 0.004*\"starlings\" + 0.003*\"way\" + 0.003*\"tree\" + 0.003*\"looked\" + 0.003*\"air\" + 0.003*\"world\" + 0.003*\"winter\"\n",
      "Topic 4: 0.005*\"long\" + 0.005*\"egg\" + 0.004*\"night\" + 0.004*\"shadow\" + 0.003*\"time\" + 0.003*\"cold\" + 0.003*\"moth\" + 0.003*\"cases\" + 0.003*\"insects\" + 0.003*\"fabre\"\n",
      "Topic 5: 0.006*\"pond\" + 0.003*\"green\" + 0.003*\"long\" + 0.003*\"sun\" + 0.003*\"spring\" + 0.003*\"new\" + 0.003*\"tree\" + 0.003*\"come\" + 0.003*\"trees\" + 0.003*\"mountains\"\n"
     ]
    }
   ],
   "source": [
    "# Print topics and their top words\n",
    "for topic_num, topic_words in lda_model.show_topics(formatted=True, num_topics=50, num_words=10):\n",
    "    print(f\"Topic {topic_num + 1}: {topic_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: fixed - Dominant Topic: {dominant_topic[0]}, Probability: {dominant_topic[1]}\n",
      "Words: long, egg, night, shadow, time, cold, moth, cases, insects, fabre\n",
      "Chapter 2: heavenearthjes - Dominant Topic: {dominant_topic[0]}, Probability: {dominant_topic[1]}\n",
      "Words: pond, green, long, sun, spring, new, tree, come, trees, mountains\n",
      "Chapter 3: kno - Dominant Topic: {dominant_topic[0]}, Probability: {dominant_topic[1]}\n",
      "Words: long, egg, night, shadow, time, cold, moth, cases, insects, fabre\n",
      "Chapter 4: seeing - Dominant Topic: {dominant_topic[0]}, Probability: {dominant_topic[1]}\n",
      "Words: eyes, snow, birds, starlings, way, tree, looked, air, world, winter\n",
      "Chapter 5: spring - Dominant Topic: {dominant_topic[0]}, Probability: {dominant_topic[1]}\n",
      "Words: pond, green, long, sun, spring, new, tree, come, trees, mountains\n",
      "Chapter 6: winter - Dominant Topic: {dominant_topic[0]}, Probability: {dominant_topic[1]}\n",
      "Words: eyes, snow, birds, starlings, way, tree, looked, air, world, winter\n"
     ]
    }
   ],
   "source": [
    "# Get the dominant topic for each chapter\n",
    "for i, chapter_bow in enumerate(corpus):\n",
    "    chapter_topics = lda_model.get_document_topics(chapter_bow)\n",
    "    dominant_topic = max(chapter_topics, key=lambda x: x[1])\n",
    "    print(f\"Chapter {i + 1}: \"+chapter_names[i]+\" - Dominant Topic: {dominant_topic[0]}, Probability: {dominant_topic[1]}\")\n",
    "    topic_words = lda_model.show_topic(dominant_topic[0], topn=10)  # Change topn to the desired number of words\n",
    "\n",
    "    # Print the words associated with the dominant topic\n",
    "    print('Words: ' + ', '.join([word for word, _ in topic_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'enable_notebook' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m enable_notebook()\n\u001b[0;32m      2\u001b[0m lda_vis \u001b[39m=\u001b[39m gensimvis\u001b[39m.\u001b[39mprepare(lda_model, corpus, dictionary)\n\u001b[0;32m      3\u001b[0m display(lda_vis)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'enable_notebook' is not defined"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "lda_vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "display(lda_vis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
